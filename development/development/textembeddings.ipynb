{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading successful\n"
     ]
    }
   ],
   "source": [
    "if not load_dotenv(\".env\"):\n",
    "    print(\"An error has occurred. Make sure the file exists and is readable\")\n",
    "else:\n",
    "    print(\"Loading successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish connection with PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def establish_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname= os.getenv(\"POSTGRES_DBNAME\"),\n",
    "            user= os.getenv(\"POSTGRES_USER\"),\n",
    "            password= os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "            host= os.getenv(\"POSTGRES_HOST\"),\n",
    "            port= os.getenv(\"POSTGRES_PORT\")\n",
    "        )\n",
    "        print(\"Success in connecting to PostgreSQL DB\")\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Check for 'passages' table\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT EXISTS (\n",
    "                SELECT 1 FROM information_schema.tables\n",
    "                WHERE table_schema = 'public' AND table_name = 'passages'\n",
    "            );\n",
    "        \"\"\")\n",
    "        table_exists_result = cur.fetchone()\n",
    "\n",
    "        if table_exists_result is None:\n",
    "            raise Exception(\"Database did not return a result for passages table existence check.\")\n",
    "        table_exists = table_exists_result[0]\n",
    "\n",
    "\n",
    "        if not table_exists:\n",
    "            print(\"Error: The 'passages' table does not exist in the database.\")\n",
    "            print(\"Please run the datapreprocessing script first to create and populate it.\")\n",
    "            if cur: cur.close()\n",
    "            if conn: conn.close()\n",
    "            return None, None\n",
    "        else:\n",
    "            # If table exists, check for 'status' column\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT EXISTS (\n",
    "                    SELECT 1 FROM information_schema.columns\n",
    "                    WHERE table_schema = 'public' AND table_name = 'passages' AND column_name = 'status'\n",
    "                );\n",
    "            \"\"\")\n",
    "            column_exists_result = cur.fetchone()\n",
    "\n",
    "            if column_exists_result is None:\n",
    "                raise Exception(\"Database did not return a result for status column existence check.\")\n",
    "            column_exists = column_exists_result[0]\n",
    "\n",
    "\n",
    "            if not column_exists:\n",
    "                print(\"Adding 'status' column to existing 'passages' table.\")\n",
    "                cur.execute(\"ALTER TABLE passages ADD COLUMN status TEXT DEFAULT 'pending_embedding';\")\n",
    "        \n",
    "                conn.commit()\n",
    "                print(\"'status' column added.\")\n",
    "\n",
    "        return conn, cur\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"A database error occurred during connection or setup check: {e}\")\n",
    "\n",
    "        if cur: \n",
    "            cur.close()\n",
    "        if conn: \n",
    "            conn.close()\n",
    "\n",
    "        return None, None\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(f\"An unexpected error occurred during DB connection/setup: {e}\")\n",
    "\n",
    "        if cur: \n",
    "            cur.close()\n",
    "        if conn: \n",
    "            conn.close()\n",
    "            \n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innitiate Pinecone, check for index, create one if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pinecone_index():\n",
    "    pc = Pinecone(api_key = os.getenv(\"PINECONE_API_KEY\"))\n",
    "    index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "    if not pc:\n",
    "        print(\"An error has occurred. Pinecone's API key not found in environmental variables\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(\"Initialize Pinecone connection\")\n",
    "        print(f\"\\nChecking for Pinecone index '{index_name}\")\n",
    "        index_list = [i.name for i in pc.list_indexes()]\n",
    "\n",
    "        # Check if the index exist\n",
    "        if index_name not in index_list:\n",
    "            print(f\"Index '{index_name}' not found. Creating the index\")\n",
    "            pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=1024,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "                embed={\n",
    "                    \"model\": \"multilingual-e5-large\",\n",
    "                    \"field_map\": {\"text\": \"text\"}   \n",
    "                }\n",
    "            )\n",
    "            print(f\"Index '{index_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Index '{index_name}' already exists. Skipping creation.\")\n",
    "\n",
    "        return pc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error has occurred during Pinecone setup or index creation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch, embed, and upsert texts from PostgreSQL onto Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_prepare_data(cur):\n",
    "    print(\"Fetching data from PostgreSQL database for passages pending embedding.\")\n",
    "    vectors_to_upsert = []\n",
    "\n",
    "    try:\n",
    "        cur.execute(\"\"\"\n",
    "                    SELECT passage_id, title, text FROM passages\n",
    "                    WHERE status = 'pending_embedding'\n",
    "                    \"\"\")\n",
    "            \n",
    "        passages = cur.fetchall()\n",
    "        print(f\"Fetched {len(passages)} passages pending embedding from the Database\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"An error has occurred when fetching passages: {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Preparing vectors for upsert\")\n",
    "    skipped_count = 0\n",
    "    if not passages:\n",
    "        print(\"No passages found with status 'pending_embedding'.\")\n",
    "        return vectors_to_upsert\n",
    "\n",
    "    for passage_id, title, text in passages:\n",
    "        if not text or not text.strip():\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        vector_id = f\"passage-{passage_id}\"\n",
    "        metadata = {\n",
    "            \"passage_id\": str(passage_id),\n",
    "            \"title\": str(title),\n",
    "            \"text\": str(text) \n",
    "        }\n",
    "\n",
    "        vectors_to_upsert.append({\n",
    "            \"id\": vector_id,\n",
    "            \"metadata\": metadata\n",
    "        })\n",
    "\n",
    "    if skipped_count > 0:\n",
    "        print(f\"Skipped {skipped_count} pending passages because of empty text\")\n",
    "        \n",
    "    print(f\"Prepare {len(vectors_to_upsert)} vectors with non-empty text\")\n",
    "    return vectors_to_upsert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone Batch Upsert "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsert vectors to Pinecone index in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_upsert(index, vectors, namespace, conn, cur, batch_size=480):\n",
    "    if not vectors:\n",
    "        print(\"No vectors to upsert\")\n",
    "        return True\n",
    "    \n",
    "    if not cur or not conn:\n",
    "        print(\"Database cursor or connection not provided to batch_upsert. Cannot update status.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Uploading {len(vectors)} vector to Pinecone namespace '{namespace}' in batches of {batch_size}\")\n",
    "    \n",
    "    all_successful = True\n",
    "    for i in tqdm(range(0, len(vectors), batch_size)):\n",
    "        batch_vectors = vectors[i:i + batch_size]\n",
    "        \n",
    "        batch_ids_to_update = []                    # Store original IDs for this batch\n",
    "        pinecone_batch = []                         # Prepare batch and collect original IDs from metadata\n",
    "\n",
    "        for vec in batch_vectors:\n",
    "            pinecone_batch.append(vec)\n",
    "\n",
    "            # Extract original passage ID from metadata for Database update\n",
    "            try:\n",
    "                original_passage_id = int(vec['metadata']['passage_id'])\n",
    "                batch_ids_to_update.append(original_passage_id)\n",
    "\n",
    "            except (KeyError, ValueError, TypeError) as e:\n",
    "                print(f\"Skipped empty batch starting at index {i}\")\n",
    "                continue\n",
    "        \n",
    "        # Attempt to upsert batch into Pinecone\n",
    "        try:\n",
    "            index.upsert(vectors=pinecone_batch, namespace=namespace)\n",
    "\n",
    "            # If upsert is successful, attempt to update status in PostgreSQL\n",
    "            if batch_ids_to_update:\n",
    "                try:\n",
    "                    update_query = \"UPDATE passages SET status = 'embedded' WHERE passage_id = ANY(%s)\"\n",
    "                    cur.execute(update_query, (batch_ids_to_update,))\n",
    "                    conn.commit()\n",
    "                    \n",
    "                except (psycopg2.Error, Exception) as db_e:\n",
    "                    print(f\"Error updating PostgreSQL status for batch starting at index {i} after successful upsert: {db_e}\")\n",
    "                    print(f\"IDs attempted to update: {batch_ids_to_update}\")\n",
    "                    conn.rollback() \n",
    "                    all_successful = False\n",
    "\n",
    "            else:\n",
    "                 print(f\"Warning: Upserted batch starting at index {i} but no valid passage IDs found to update status.\")\n",
    "\n",
    "        except Exception as pinecone_e:\n",
    "            print(f\"Error in batch upsert: {pinecone_e}\")\n",
    "            all_successful = False\n",
    "\n",
    "    if all_successful:\n",
    "        print(f\"Successfully uploaded {len(vectors)} vectors onto Pinecone.\")\n",
    "    else:\n",
    "        print(\"Batch upload process finished with errors.\")\n",
    "\n",
    "    return all_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in connecting to PostgreSQL DB\n",
      "Initialize text embedding process\n",
      "Initialize Pinecone connection\n",
      "\n",
      "Checking for Pinecone index 'ielts-rag\n",
      "Index 'ielts-rag' already exists. Skipping creation.\n",
      "Connected to Pinecone index 'ielts-rag'.\n",
      "Fetching passages pending embedding from namespace 'ielts-passages'...\n",
      "Fetching data from PostgreSQL database for passages pending embedding.\n",
      "Fetched 2075 passages pending embedding from the Database\n",
      "Preparing vectors for upsert\n",
      "Prepare 2075 vectors with non-empty text\n",
      "Found 2075 vectors to upsert.\n",
      "Uploading 2075 vector to Pinecone namespace 'ielts-passages' in batches of 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 3458.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch upsert: At least one of 'values' or 'sparse_values' must be provided in the vector dictionary.\n",
      "Error in batch upsert: At least one of 'values' or 'sparse_values' must be provided in the vector dictionary.\n",
      "Error in batch upsert: At least one of 'values' or 'sparse_values' must be provided in the vector dictionary.\n",
      "Error in batch upsert: At least one of 'values' or 'sparse_values' must be provided in the vector dictionary.\n",
      "Error in batch upsert: At least one of 'values' or 'sparse_values' must be provided in the vector dictionary.\n",
      "Batch upload process finished with errors.\n",
      "\n",
      "Closing database connection\n",
      "Database cursor closed.\n",
      "Database connection closed.\n",
      "\n",
      "Complete the Text Embedding process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    conn, cur = establish_connection()\n",
    "    print(\"Initialize text embedding process\")\n",
    "\n",
    "    if conn and cur:\n",
    "        try:\n",
    "            pinecone_client = setup_pinecone_index()\n",
    "            if pinecone_client:\n",
    "                index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "                namespace = os.getenv(\"PINECONE_NAMESPACE\")\n",
    "\n",
    "                index = pinecone_client.Index(index_name)\n",
    "                print(f\"Connected to Pinecone index '{index_name}'.\")\n",
    "\n",
    "                # Fetch and Prepare Data for Pending Passages\n",
    "                print(f\"Fetching passages pending embedding from namespace '{namespace}'...\")\n",
    "                vectors = fetch_and_prepare_data(cur)\n",
    "                \n",
    "                # Upsertting data \n",
    "                if vectors is not None:\n",
    "                    if vectors: \n",
    "                        print(f\"Found {len(vectors)} vectors to upsert.\")\n",
    "                        batch_upsert(index, vectors, namespace, conn, cur)\n",
    "\n",
    "                    else:\n",
    "                        print(f\"No passages found in status 'pending_embedding'. Nothing to upsert.\")\n",
    "                else:\n",
    "                    print(\"An error has occurred. Skipping upsert because data fetching or preparation failed.\")\n",
    "\n",
    "            else: \n",
    "                 print(\"An error has occurred. Skipping main logic due to Pinecone setup failure.\")\n",
    "\n",
    "        # CCatches other potential errors\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during execution: {e}\")\n",
    "\n",
    "        # Cleanup Block (Always Executes if connection succeeded initially)\n",
    "        finally:\n",
    "            print(\"\\nClosing database connection\")\n",
    "            try:\n",
    "                if cur:\n",
    "                    cur.close()\n",
    "                    print(\"Database cursor closed.\")\n",
    "                if conn:\n",
    "                    conn.close()\n",
    "                    print(\"Database connection closed.\")\n",
    "            except (psycopg2.Error, Exception) as e:\n",
    "                print(f\"Error closing database connection: {e}\")\n",
    "    else:\n",
    "        print(\"An error has occurred. Database connection could not be established during setup.\")\n",
    "\n",
    "    print(\"\\nComplete the Text Embedding process.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
